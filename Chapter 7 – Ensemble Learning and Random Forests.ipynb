{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 学习器集成--一个训练集多个分类器"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "1、硬投票：分类最多的作为结果返回  \n",
        "2、软投票：分类器权重×分类器结果概率再取均值，最后概率值最大的类别为结果返回"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons\n",
        "X, y = make_moons(n_samples=500,noise=.3,random_state=42)\n",
        "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "log_clf = LogisticRegression(solver='liblinear',random_state=42)\n",
        "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
        "svm_clf = SVC(gamma='auto',random_state=42)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "voting_clf_hard = VotingClassifier(\n",
        "estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
        "voting='hard')\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf_hard):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.872\n",
            "SVC 0.888\n",
            "VotingClassifier 0.896\n"
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "svm_clf = SVC(gamma='auto',random_state=42,probability=True)\n",
        "\n",
        "voting_clf_soft = VotingClassifier(\n",
        "estimators=[('lr',log_clf),('rf',rnd_clf),('svc',svm_clf)],\n",
        "voting='soft')\n",
        "\n",
        "for clf in (log_clf, rnd_clf, svm_clf, voting_clf_soft):\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LogisticRegression 0.864\n",
            "RandomForestClassifier 0.872\n",
            "SVC 0.888\n",
            "VotingClassifier 0.912\n"
          ]
        }
      ],
      "execution_count": 31,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 训练集集成--不同训练集相同分类器"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "1、有放回采样--Bagging  \n",
        "2、无放回采样--pasting"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(),\n",
        "                            n_estimators=500,max_samples=100,\n",
        "                            bootstrap=True,n_jobs=-1,random_state=42)\n",
        "bag_clf.fit(X_train,y_train)\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "0.904"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tree_clf = DecisionTreeClassifier(random_state=42)\n",
        "tree_clf.fit(X_train,y_train)\n",
        "y_pred_tree = tree_clf.predict(X_test)\n",
        "accuracy_score(y_test,y_pred_tree)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "0.856"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Bagging采样方法是对m个实例的训练集，有放回抽样m次。；因此对每个样本，m次都未选中的概率是(1-1/m)**m。当m越大，此概率趋近1/e=0.37，即m次中至少1次选中的概率是0.632。\n",
        "# m中包含实例a1~am,令xi=0(ai未选中）或1（ai选中至少1次），sum(xi)就是m中被选中过的实例数。sum(xi)的期望就是选中过的实例数的平均值，即m个(1*0.632+0*0.368)的和，为0.632m个实例。"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "(1-1/1e10)**1e10"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": [
              "0.36787941071455793"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# out of bag 评估\n",
        "bag_clf = BaggingClassifier(DecisionTreeClassifier(random_state=42),n_estimators=500,bootstrap=True,n_jobs=-1,oob_score=True,random_state=40)\n",
        "bag_clf.fit(X_train,y_train)\n",
        "bag_clf.oob_score_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": [
              "0.9013333333333333"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 返回决策函数的每个实例类别概率\n",
        "bag_clf.oob_decision_function_"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "array([[0.31746032, 0.68253968],\n",
              "       [0.34117647, 0.65882353],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.08379888, 0.91620112],\n",
              "       [0.31693989, 0.68306011],\n",
              "       [0.02923977, 0.97076023],\n",
              "       [0.97687861, 0.02312139],\n",
              "       [0.97765363, 0.02234637],\n",
              "       [0.74404762, 0.25595238],\n",
              "       [0.        , 1.        ],\n",
              "       [0.71195652, 0.28804348],\n",
              "       [0.83957219, 0.16042781],\n",
              "       [0.97777778, 0.02222222],\n",
              "       [0.0625    , 0.9375    ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97297297, 0.02702703],\n",
              "       [0.95238095, 0.04761905],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01704545, 0.98295455],\n",
              "       [0.38947368, 0.61052632],\n",
              "       [0.88700565, 0.11299435],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96685083, 0.03314917],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99428571, 0.00571429],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.64804469, 0.35195531],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.13402062, 0.86597938],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.36065574, 0.63934426],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.27093596, 0.72906404],\n",
              "       [0.34146341, 0.65853659],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.98265896, 0.01734104],\n",
              "       [0.91428571, 0.08571429],\n",
              "       [0.97282609, 0.02717391],\n",
              "       [0.97029703, 0.02970297],\n",
              "       [0.        , 1.        ],\n",
              "       [0.06134969, 0.93865031],\n",
              "       [0.98019802, 0.01980198],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.97790055, 0.02209945],\n",
              "       [0.79473684, 0.20526316],\n",
              "       [0.41919192, 0.58080808],\n",
              "       [0.99473684, 0.00526316],\n",
              "       [0.        , 1.        ],\n",
              "       [0.67613636, 0.32386364],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.87356322, 0.12643678],\n",
              "       [1.        , 0.        ],\n",
              "       [0.56140351, 0.43859649],\n",
              "       [0.16304348, 0.83695652],\n",
              "       [0.67539267, 0.32460733],\n",
              "       [0.90673575, 0.09326425],\n",
              "       [0.        , 1.        ],\n",
              "       [0.16201117, 0.83798883],\n",
              "       [0.89005236, 0.10994764],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.995     , 0.005     ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07272727, 0.92727273],\n",
              "       [0.05418719, 0.94581281],\n",
              "       [0.29533679, 0.70466321],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.81871345, 0.18128655],\n",
              "       [0.01092896, 0.98907104],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.22513089, 0.77486911],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.9368932 , 0.0631068 ],\n",
              "       [0.76536313, 0.23463687],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.17127072, 0.82872928],\n",
              "       [0.65306122, 0.34693878],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03076923, 0.96923077],\n",
              "       [0.49444444, 0.50555556],\n",
              "       [1.        , 0.        ],\n",
              "       [0.02673797, 0.97326203],\n",
              "       [0.98870056, 0.01129944],\n",
              "       [0.23121387, 0.76878613],\n",
              "       [0.5       , 0.5       ],\n",
              "       [0.9947644 , 0.0052356 ],\n",
              "       [0.00555556, 0.99444444],\n",
              "       [0.98963731, 0.01036269],\n",
              "       [0.25641026, 0.74358974],\n",
              "       [0.92972973, 0.07027027],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.80681818, 0.19318182],\n",
              "       [1.        , 0.        ],\n",
              "       [0.0106383 , 0.9893617 ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01036269, 0.98963731],\n",
              "       [0.97752809, 0.02247191],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.01960784, 0.98039216],\n",
              "       [0.18367347, 0.81632653],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.29533679, 0.70466321],\n",
              "       [0.98295455, 0.01704545],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00561798, 0.99438202],\n",
              "       [0.75138122, 0.24861878],\n",
              "       [0.38624339, 0.61375661],\n",
              "       [0.42708333, 0.57291667],\n",
              "       [0.86315789, 0.13684211],\n",
              "       [0.92964824, 0.07035176],\n",
              "       [0.05699482, 0.94300518],\n",
              "       [0.82802548, 0.17197452],\n",
              "       [0.01546392, 0.98453608],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02298851, 0.97701149],\n",
              "       [0.96721311, 0.03278689],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01041667, 0.98958333],\n",
              "       [0.        , 1.        ],\n",
              "       [0.0326087 , 0.9673913 ],\n",
              "       [0.01020408, 0.98979592],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93785311, 0.06214689],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.99462366, 0.00537634],\n",
              "       [0.        , 1.        ],\n",
              "       [0.38860104, 0.61139896],\n",
              "       [0.32065217, 0.67934783],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.31182796, 0.68817204],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00588235, 0.99411765],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.62264151, 0.37735849],\n",
              "       [0.92344498, 0.07655502],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99526066, 0.00473934],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98888889, 0.01111111],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.06451613, 0.93548387],\n",
              "       [1.        , 0.        ],\n",
              "       [0.05154639, 0.94845361],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.03278689, 0.96721311],\n",
              "       [1.        , 0.        ],\n",
              "       [0.95808383, 0.04191617],\n",
              "       [0.79532164, 0.20467836],\n",
              "       [0.55665025, 0.44334975],\n",
              "       [0.        , 1.        ],\n",
              "       [0.18604651, 0.81395349],\n",
              "       [1.        , 0.        ],\n",
              "       [0.93121693, 0.06878307],\n",
              "       [0.97740113, 0.02259887],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00531915, 0.99468085],\n",
              "       [0.        , 1.        ],\n",
              "       [0.44623656, 0.55376344],\n",
              "       [0.86363636, 0.13636364],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.00558659, 0.99441341],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96923077, 0.03076923],\n",
              "       [0.        , 1.        ],\n",
              "       [0.21649485, 0.78350515],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98477157, 0.01522843],\n",
              "       [0.8       , 0.2       ],\n",
              "       [0.99441341, 0.00558659],\n",
              "       [0.        , 1.        ],\n",
              "       [0.08379888, 0.91620112],\n",
              "       [0.98984772, 0.01015228],\n",
              "       [0.01142857, 0.98857143],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02747253, 0.97252747],\n",
              "       [1.        , 0.        ],\n",
              "       [0.79144385, 0.20855615],\n",
              "       [0.        , 1.        ],\n",
              "       [0.90804598, 0.09195402],\n",
              "       [0.98387097, 0.01612903],\n",
              "       [0.20634921, 0.79365079],\n",
              "       [0.19767442, 0.80232558],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.20338983, 0.79661017],\n",
              "       [0.98181818, 0.01818182],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.98969072, 0.01030928],\n",
              "       [0.        , 1.        ],\n",
              "       [0.48663102, 0.51336898],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.07821229, 0.92178771],\n",
              "       [0.11176471, 0.88823529],\n",
              "       [0.99415205, 0.00584795],\n",
              "       [0.03015075, 0.96984925],\n",
              "       [1.        , 0.        ],\n",
              "       [0.40837696, 0.59162304],\n",
              "       [0.04891304, 0.95108696],\n",
              "       [0.51595745, 0.48404255],\n",
              "       [0.51898734, 0.48101266],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.59903382, 0.40096618],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.24157303, 0.75842697],\n",
              "       [0.81052632, 0.18947368],\n",
              "       [0.08717949, 0.91282051],\n",
              "       [0.99453552, 0.00546448],\n",
              "       [0.82142857, 0.17857143],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.125     , 0.875     ],\n",
              "       [0.04712042, 0.95287958],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.89150943, 0.10849057],\n",
              "       [0.1978022 , 0.8021978 ],\n",
              "       [0.95238095, 0.04761905],\n",
              "       [0.00515464, 0.99484536],\n",
              "       [0.609375  , 0.390625  ],\n",
              "       [0.07692308, 0.92307692],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.84210526, 0.15789474],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99484536, 0.00515464],\n",
              "       [0.95876289, 0.04123711],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.26903553, 0.73096447],\n",
              "       [0.98461538, 0.01538462],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00574713, 0.99425287],\n",
              "       [0.85142857, 0.14857143],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.76506024, 0.23493976],\n",
              "       [0.8969697 , 0.1030303 ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.73333333, 0.26666667],\n",
              "       [0.47727273, 0.52272727],\n",
              "       [0.        , 1.        ],\n",
              "       [0.92473118, 0.07526882],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.87709497, 0.12290503],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.74752475, 0.25247525],\n",
              "       [0.09146341, 0.90853659],\n",
              "       [0.44329897, 0.55670103],\n",
              "       [0.22395833, 0.77604167],\n",
              "       [0.        , 1.        ],\n",
              "       [0.87046632, 0.12953368],\n",
              "       [0.78212291, 0.21787709],\n",
              "       [0.00507614, 0.99492386],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.02884615, 0.97115385],\n",
              "       [0.96571429, 0.03428571],\n",
              "       [0.93478261, 0.06521739],\n",
              "       [1.        , 0.        ],\n",
              "       [0.49756098, 0.50243902],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.01604278, 0.98395722],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.96987952, 0.03012048],\n",
              "       [0.        , 1.        ],\n",
              "       [0.05747126, 0.94252874],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.98989899, 0.01010101],\n",
              "       [0.01675978, 0.98324022],\n",
              "       [1.        , 0.        ],\n",
              "       [0.13541667, 0.86458333],\n",
              "       [0.        , 1.        ],\n",
              "       [0.00546448, 0.99453552],\n",
              "       [0.        , 1.        ],\n",
              "       [0.41836735, 0.58163265],\n",
              "       [0.11309524, 0.88690476],\n",
              "       [0.22110553, 0.77889447],\n",
              "       [1.        , 0.        ],\n",
              "       [0.97647059, 0.02352941],\n",
              "       [0.22826087, 0.77173913],\n",
              "       [0.98882682, 0.01117318],\n",
              "       [0.        , 1.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [1.        , 0.        ],\n",
              "       [0.96428571, 0.03571429],\n",
              "       [0.33507853, 0.66492147],\n",
              "       [0.98235294, 0.01764706],\n",
              "       [1.        , 0.        ],\n",
              "       [0.        , 1.        ],\n",
              "       [0.99465241, 0.00534759],\n",
              "       [0.        , 1.        ],\n",
              "       [0.06043956, 0.93956044],\n",
              "       [0.97619048, 0.02380952],\n",
              "       [1.        , 0.        ],\n",
              "       [0.03108808, 0.96891192],\n",
              "       [0.57291667, 0.42708333]])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": true,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "y_pred = bag_clf.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "0.912"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BaggingClassifier 的随机贴片/随机子空间  \n",
        "随机贴片：对训练实例和特征的采样  \n",
        "随机子空间：对特征采样（bootstrap_features=True并且/或者max_features小于 1.0）  \n",
        "采样特征导致更多的预测多样性，用高偏差换低方差。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 随机森林  \n",
        "可以方便了解特征重要度，特别是特征选择时候"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
        "rnd_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rnd_clf.predict(X_test)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#以下bagging类似上面的randomforestclassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "DTC = DecisionTreeClassifier(splitter='random',max_leaf_nodes=16)\n",
        "bag_clf = BaggingClassifier(DTC,n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 极端随机树"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "在每个节点分裂时只考虑随机特征值上的特征  \n",
        "也是用高偏差换低方差，训练更快  "
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 特征重要度"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# feature_importance_属性\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "rnd_clf = RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
        "rnd_clf.fit(iris['data'],iris['target'])\n",
        "for name, score in sorted(zip(iris['feature_names'],rnd_clf.feature_importances_)):\n",
        "    print(name,score)\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "petal length (cm) 0.45344639318712826\n",
            "petal width (cm) 0.43281266247668565\n",
            "sepal length (cm) 0.09014903436281974\n",
            "sepal width (cm) 0.023591909973366125\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "mnist.target = mnist.target.astype(np.int64)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rnd_clf = RandomForestClassifier(n_estimators=10,random_state=42)\n",
        "rnd_clf.fit(mnist.data, mnist.target)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
              "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
              "            oob_score=False, random_state=42, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "def plot_digit(data):\n",
        "    image = data.reshape(28, 28)\n",
        "    plt.imshow(image, cmap = mpl.cm.hot,interpolation=\"nearest\")\n",
        "    plt.axis(\"off\")"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plot_digit(rnd_clf.feature_importances_)\n",
        "cbar = plt.colorbar(ticks=[rnd_clf.feature_importances_.min(), rnd_clf.feature_importances_.max()])\n",
        "cbar.ax.set_yticklabels(['Not important', 'Very important'])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 11,
          "data": {
            "text/plain": [
              "[Text(1, 0, 'Not important'), Text(1, 0, 'Very important')]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": [
              "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\n"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 学习器集成--提升  \n",
        "## 适应性提升：AdaBoost  \n",
        "新分类器的训练集是上一个分类器的y_pred与y_train对照过的加权后的训练集，原理是对之前分类结果不对的训练实例多加关注  \n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "ada_clf = AdaBoostClassifier(\n",
        "  DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
        "  learning_rate=0.5, random_state=42)\n",
        "ada_clf.fit(X_train, y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": [
              "AdaBoostClassifier(algorithm='SAMME.R',\n",
              "          base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=1,\n",
              "            max_features=None, max_leaf_nodes=None,\n",
              "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "            min_samples_leaf=1, min_samples_split=2,\n",
              "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
              "            splitter='best'),\n",
              "          learning_rate=0.5, n_estimators=200, random_state=42)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#模拟实现\n",
        "m = len(X_train)\n",
        "sample_weights=np.ones(m)\n",
        "for i in range(5):\n",
        "  svm_clf = SVC(kernel=\"rbf\", C=0.05, gamma=\"auto\", random_state=42)\n",
        "  svm_clf.fit(X_train,y_train,sample_weight=sample_weights)\n",
        "  y_pred = svm_clf.predict(X_train)\n",
        "  sample_weights[y_pred!=y_train] *= 1.5"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 梯度提升:Gradient Boosting  \n",
        "超参数learning_rate 确立了每个树的贡献。  \n",
        "如果你把它设置为一个很小的树，例如 0.1，在集成中就需要更多的树去拟合训练集，但预测通常会更好。这个正则化技术叫做 shrinkage。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "##梯度提升的弱学习器设定，限定了baseEstimator只能为决策树\n",
        "gbrt = GradientBoostingRegressor(max_depth=2,n_estimators=3,learning_rate=1,random_state=42)\n",
        "gbrt.fit(X,y)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": [
              "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
              "             learning_rate=1, loss='ls', max_depth=2, max_features=None,\n",
              "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
              "             min_impurity_split=None, min_samples_leaf=1,\n",
              "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
              "             n_estimators=3, n_iter_no_change=None, presort='auto',\n",
              "             random_state=42, subsample=1.0, tol=0.0001,\n",
              "             validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 模拟实现\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) - 0.5\n",
        "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)\n",
        "\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "tree_reg1 = DecisionTreeRegressor(max_depth=2,random_state=42)\n",
        "tree_reg1.fit(X, y)\n",
        "\n",
        "y2 = y - tree_reg1.predict(X)\n",
        "tree_reg2 = DecisionTreeRegressor(max_depth=2,random_state=42)\n",
        "tree_reg2.fit(X, y2)\n",
        "\n",
        "y3 = y2 - tree_reg2.predict(X)\n",
        "tree_reg3 = DecisionTreeRegressor(max_depth=2, random_state=42)\n",
        "tree_reg3.fit(X, y3)\n",
        "\n",
        "X_new = np.array([[0.8]])\n",
        "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))\n",
        "y_pred"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": [
              "array([0.75026781])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 梯度提升的早期停止法  \n",
        "自带的staged_predict()方法"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X,y,random_state=49)\n",
        "\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, n_estimators=120, random_state=42)\n",
        "gbrt.fit(X_train,y_train)\n",
        "\n",
        "errors = [mean_squared_error(y_val,y_pred) for y_pred in gbrt.staged_predict(X_val)]\n",
        "\n",
        "best_n_estimators = np.argmin(errors)+1\n",
        "min_error = np.min(errors)"
      ],
      "outputs": [],
      "execution_count": 20,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(errors),min_error,best_n_estimators)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "120 0.002712853325235463 56\n"
          ]
        }
      ],
      "execution_count": 21,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gbrt_best = GradientBoostingRegressor(max_depth=2,n_estimators=best_n_estimators, random_state=42)\n",
        "gbrt_best.fit(X_train, y_train)\n",
        "y_pred = gbrt_best.predict(X_val)\n",
        "mean_squared_error(y_val,y_pred)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": [
              "0.002712853325235463"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 22,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_n_estimators"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": [
              "56"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 23,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(11, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(errors, \"b.-\")\n",
        "plt.plot([best_n_estimators, best_n_estimators], [0, min_error], \"k--\")\n",
        "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
        "plt.plot(best_n_estimators, min_error, \"ko\")\n",
        "plt.text(best_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
        "plt.axis([0, 120, 0, 0.01])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.title(\"Validation error\", fontsize=14)\n",
        "\n",
        "\n",
        "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500)\n",
        "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
        "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
        "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
        "    if label or data_label:\n",
        "        plt.legend(loc=\"upper center\", fontsize=16)\n",
        "    plt.axis(axes)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
        "plt.title(\"Best model (%d trees)\" % best_n_estimators, fontsize=14)\n"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 24,
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Best model (56 trees)')"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 24,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(11, 4))\n",
        "\n",
        "plt.subplot(121)\n",
        "plt.plot(errors, \"b.-\")\n",
        "plt.plot([best_n_estimators, best_n_estimators], [0, min_error], \"k--\")\n",
        "plt.plot([0, 120], [min_error, min_error], \"k--\")\n",
        "plt.plot(best_n_estimators, min_error, \"ko\")\n",
        "plt.text(best_n_estimators, min_error*1.2, \"Minimum\", ha=\"center\", fontsize=14)\n",
        "plt.axis([0, 120, 0, 0.01])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.title(\"Validation error\", fontsize=14)\n",
        "\n",
        "\n",
        "def plot_predictions(regressors, X, y, axes, label=None, style=\"r-\", data_style=\"b.\", data_label=None):\n",
        "    x1 = np.linspace(axes[0], axes[1], 500)\n",
        "    y_pred = sum(regressor.predict(x1.reshape(-1, 1)) for regressor in regressors)\n",
        "    plt.plot(X[:, 0], y, data_style, label=data_label)\n",
        "    plt.plot(x1, y_pred, style, linewidth=2, label=label)\n",
        "    if label or data_label:\n",
        "        plt.legend(loc=\"upper center\", fontsize=16)\n",
        "    plt.axis(axes)\n",
        "\n",
        "plt.subplot(122)\n",
        "plot_predictions([gbrt_best], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
        "plt.title(\"Best model (%d trees)\" % best_n_estimators, fontsize=14)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "模拟方法  \n",
        "可以通过设置warm_start=True来实现 ，  \n",
        "这使得当fit()方法被调用时 sklearn 保留现有树，并允许增量训练。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "#结果与上相同\n",
        "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True, random_state=42)\n",
        "\n",
        "min_val_error = float(\"inf\")\n",
        "error_going_up = 0\n",
        "for n_estimators in range(1, 120):\n",
        "    gbrt.n_estimators = n_estimators\n",
        "    gbrt.fit(X_train, y_train)\n",
        "    y_pred = gbrt.predict(X_val)\n",
        "    val_error = mean_squared_error(y_val, y_pred)\n",
        "    print(n_estimators,val_error)\n",
        "    if val_error < min_val_error:\n",
        "        min_val_error = val_error\n",
        "        error_going_up = 0\n",
        "    else:\n",
        "        error_going_up += 1\n",
        "        if error_going_up == 5:\n",
        "            break \n",
        "            \n",
        "print(gbrt.n_estimators, \"Minimum validation MSE:\", min_val_error)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 0.03976434066090687\n",
            "2 0.03301153878946109\n",
            "3 0.027663386192027795\n",
            "4 0.023337263188229852\n",
            "5 0.020390590545872743\n",
            "6 0.017820174421765502\n",
            "7 0.015262814214454865\n",
            "8 0.013228529533567415\n",
            "9 0.011758450328306618\n",
            "10 0.010288335529306629\n",
            "11 0.009391268210618017\n",
            "12 0.008605826199167754\n",
            "13 0.007745553291052828\n",
            "14 0.007083571270654957\n",
            "15 0.006766296135021012\n",
            "16 0.006116142333014483\n",
            "17 0.005770219779341232\n",
            "18 0.005416351332327169\n",
            "19 0.0050727394710244665\n",
            "20 0.0048159263120028765\n",
            "21 0.004357591913537005\n",
            "22 0.004192866645244622\n",
            "23 0.0039670672414243964\n",
            "24 0.0038463154458755833\n",
            "25 0.0037468374981679863\n",
            "26 0.003530909744387239\n",
            "27 0.0034677533859285626\n",
            "28 0.0033882676886440523\n",
            "29 0.003224220772589744\n",
            "30 0.0031883136637545035\n",
            "31 0.003166151135979498\n",
            "32 0.003072276914292378\n",
            "33 0.003024919266015998\n",
            "34 0.002991089248190895\n",
            "35 0.002957301355498197\n",
            "36 0.0028890741785044197\n",
            "37 0.0028849656803361795\n",
            "38 0.0028902935070124736\n",
            "39 0.002836717946434534\n",
            "40 0.0028151139950619727\n",
            "41 0.002805906789900023\n",
            "42 0.002769821491376303\n",
            "43 0.002775136129921357\n",
            "44 0.002778984340830943\n",
            "45 0.0027422856408325373\n",
            "46 0.002735774633470487\n",
            "47 0.0027433438627545155\n",
            "48 0.002729985019758056\n",
            "49 0.002739928056372175\n",
            "50 0.002745683538485092\n",
            "51 0.002737002470147249\n",
            "52 0.0027205012064232207\n",
            "53 0.0027176421276560465\n",
            "54 0.0027195073111332528\n",
            "55 0.00272625716783103\n",
            "56 0.002712853325235463\n",
            "57 0.002719454272122578\n",
            "58 0.0027133799581649065\n",
            "59 0.0027221277186536084\n",
            "60 0.0027136110678215226\n",
            "61 0.002721390321329206\n",
            "61 Minimum validation MSE: 0.002712853325235463\n"
          ]
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "min_error"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": [
              "0.002712853325235463"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 29,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "随机梯度提升方法  \n",
        "GradientBoostingRegressor也支持指定用于训练每棵树的训练实例比例的超参数subsample。例如如果subsample=0.25，那么每个树都会在 25% 随机选择的训练实例上训练。你现在也能猜出来，这也是个高偏差换低方差的作用。它同样也加速了训练。这个技术叫做随机梯度提升。"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 梯度提升：XGBoost"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
        "xgb_reg.fit(X_train,y_train)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "print(\"Validation MSE:\", mean_squared_error(y_val,y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation MSE: 0.0028512559726563943\n"
          ]
        }
      ],
      "execution_count": 25,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 早期停止法\n",
        "xgb_reg.fit(X_train,y_train,eval_set=[(X_val,y_val)],early_stopping_rounds=5)\n",
        "y_pred = xgb_reg.predict(X_val)\n",
        "print(\"Validation MSE:\", mean_squared_error(y_val,y_pred))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0]\tvalidation_0-rmse:0.286719\n",
            "Will train until validation_0-rmse hasn't improved in 5 rounds.\n",
            "[1]\tvalidation_0-rmse:0.258221\n",
            "[2]\tvalidation_0-rmse:0.232634\n",
            "[3]\tvalidation_0-rmse:0.210526\n",
            "[4]\tvalidation_0-rmse:0.190232\n",
            "[5]\tvalidation_0-rmse:0.172196\n",
            "[6]\tvalidation_0-rmse:0.156394\n",
            "[7]\tvalidation_0-rmse:0.142241\n",
            "[8]\tvalidation_0-rmse:0.129789\n",
            "[9]\tvalidation_0-rmse:0.118752\n",
            "[10]\tvalidation_0-rmse:0.108388\n",
            "[11]\tvalidation_0-rmse:0.100155\n",
            "[12]\tvalidation_0-rmse:0.09208\n",
            "[13]\tvalidation_0-rmse:0.084791\n",
            "[14]\tvalidation_0-rmse:0.078699\n",
            "[15]\tvalidation_0-rmse:0.073248\n",
            "[16]\tvalidation_0-rmse:0.069391\n",
            "[17]\tvalidation_0-rmse:0.066277\n",
            "[18]\tvalidation_0-rmse:0.063458\n",
            "[19]\tvalidation_0-rmse:0.060326\n",
            "[20]\tvalidation_0-rmse:0.0578\n",
            "[21]\tvalidation_0-rmse:0.055643\n",
            "[22]\tvalidation_0-rmse:0.053943\n",
            "[23]\tvalidation_0-rmse:0.053138\n",
            "[24]\tvalidation_0-rmse:0.052415\n",
            "[25]\tvalidation_0-rmse:0.051821\n",
            "[26]\tvalidation_0-rmse:0.051226\n",
            "[27]\tvalidation_0-rmse:0.051135\n",
            "[28]\tvalidation_0-rmse:0.05091\n",
            "[29]\tvalidation_0-rmse:0.050893\n",
            "[30]\tvalidation_0-rmse:0.050725\n",
            "[31]\tvalidation_0-rmse:0.050471\n",
            "[32]\tvalidation_0-rmse:0.050285\n",
            "[33]\tvalidation_0-rmse:0.050492\n",
            "[34]\tvalidation_0-rmse:0.050348\n",
            "[35]\tvalidation_0-rmse:0.050319\n",
            "[36]\tvalidation_0-rmse:0.050271\n",
            "[37]\tvalidation_0-rmse:0.050318\n",
            "[38]\tvalidation_0-rmse:0.050502\n",
            "[39]\tvalidation_0-rmse:0.050428\n",
            "[40]\tvalidation_0-rmse:0.050716\n",
            "[41]\tvalidation_0-rmse:0.050842\n",
            "Stopping. Best iteration:\n",
            "[36]\tvalidation_0-rmse:0.050271\n",
            "\n",
            "Validation MSE: 0.002527133207154657\n"
          ]
        }
      ],
      "execution_count": 26,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_predictions([xgb_reg], X, y, axes=[-0.5, 0.5, -0.1, 0.8])\n",
        "# plt.title(\"Best model (%d trees)\" % best_n_estimators, fontsize=14)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": 27,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit xgboost.XGBRegressor().fit(X_train,y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5.08 ms ± 76.6 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "execution_count": 28,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%timeit GradientBoostingRegressor().fit(X_train,y_train)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10.4 ms ± 42.7 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
          ]
        }
      ],
      "execution_count": 30,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Voting Classifier"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": 31,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stacking Ensemble"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "toc": {
      "toc_position": {},
      "skip_h1_title": false,
      "number_sections": true,
      "title_cell": "Table of Contents",
      "toc_window_display": false,
      "base_numbering": 1,
      "toc_section_display": true,
      "title_sidebar": "Contents",
      "toc_cell": false,
      "nav_menu": {},
      "sideBar": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.14.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}